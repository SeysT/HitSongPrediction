{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31034, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from csv import reader\n",
    "\n",
    "data = pd.read_csv('./Data/dataset.csv', delimiter='\\t')\n",
    "\n",
    "# On supprime champs non pertinents\n",
    "data = data.drop(['duration', 'artist_terms_freq', 'artist_id', 'artist_terms_weight', 'danceability', 'energy', 'path', 'file', 'similar_artists', 'title', 'year', 'latitude', 'longitude', 'midi_name'], axis=1)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# On supprime les données sans hotttnesss ou avec hotttnesss = 0 (non calculée)\n",
    "data = data.dropna(axis=0, how='any')\n",
    "data = data[data['hotttnesss'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        artist_terms  key  mode  loudness  \\\n",
      "2  [b'hard rock' b'heavy metal' b'blues-rock' b'c...    7     1    -5.271   \n",
      "5  [b'folk rock' b'singer-songwriter' b'rock' b'a...    2     1   -15.164   \n",
      "6  [b'soft rock' b'blues-rock' b'pop rock' b'coun...    9     1    -8.531   \n",
      "7  [b'outlaw country' b'country rock' b'southern ...    9     1    -6.291   \n",
      "9  [b'hip hop' b'rap' b'funk' b'r&b' b'pop' b'sou...   11     0    -4.882   \n",
      "\n",
      "     tempo  artist_familiarity  hotttnesss  \n",
      "2  150.062            0.707200    0.684136  \n",
      "5  103.905            0.775320    0.830423  \n",
      "6  180.149            0.643183    0.767728  \n",
      "7  185.061            0.138188    0.215080  \n",
      "9  105.206            0.845602    0.624425  \n",
      "(13151, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ajout de genres principaux\n",
    "\n",
    "data['rock'] = data['artist_terms'].apply(lambda x: int('rock' in x))\n",
    "data['pop'] = data['artist_terms'].apply(lambda x: int('pop' in x))\n",
    "data['rap'] = data['artist_terms'].apply(lambda x: int('rap' in x))\n",
    "data['country'] = data['artist_terms'].apply(lambda x: int('country' in x))\n",
    "data['classical'] = data['artist_terms'].apply(lambda x: int('classical' in x))\n",
    "data['jazz'] = data['artist_terms'].apply(lambda x: int('jazz' in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on donne le label '1' aux chansons dont la hotttnesss est supérieure ou égale à un seuil\n",
    "threshold = 0.5\n",
    "data['hit_song'] = data['hotttnesss'].apply(lambda x: int(x >= threshold))\n",
    "data['non_hit_song'] = data['hotttnesss'].apply(lambda x: int(x < threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on laisse de côté le champ \"artist_terms\" qui est non numérique, et hotttnesss\n",
    "data = data.drop(['artist_terms', 'hotttnesss'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key  mode  loudness    tempo  artist_familiarity  rock  pop  rap  country  \\\n",
      "2    7     1    -5.271  150.062            0.707200     1    1    0        1   \n",
      "5    2     1   -15.164  103.905            0.775320     1    1    0        0   \n",
      "6    9     1    -8.531  180.149            0.643183     1    1    0        1   \n",
      "7    9     1    -6.291  185.061            0.138188     1    1    0        1   \n",
      "9   11     0    -4.882  105.206            0.845602     0    1    1        0   \n",
      "\n",
      "   classical  jazz  hit_song  non_hit_song  \n",
      "2          0     1         1             0  \n",
      "5          0     0         1             0  \n",
      "6          0     1         1             0  \n",
      "7          0     1         0             1  \n",
      "9          0     0         1             0  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dimensions of dataset\n",
    "n = data.shape[0]\n",
    "p = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on convertit data en array numpy\n",
    "data = data.values\n",
    "\n",
    "# on change toutes les valeurs en positif\n",
    "data = np.absolute(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on divise chaque colonne par le max de cettte colonne pour que chaque entrée soit comprise entre 0 et 1\n",
    "data = data*1./np.max(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63636364 1.         0.11914288 ... 1.         1.         0.        ]\n",
      " [0.18181818 1.         0.34275898 ... 0.         1.         0.        ]\n",
      " [0.81818182 1.         0.19283018 ... 1.         1.         0.        ]\n",
      " ...\n",
      " [0.81818182 1.         0.29477182 ... 0.         1.         0.        ]\n",
      " [0.09090909 1.         0.49377274 ... 0.         0.         1.        ]\n",
      " [0.36363636 1.         0.10682399 ... 1.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# données d'entraînement, de test et de validation\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.7*n))\n",
    "test_start = train_end\n",
    "test_end = int(np.floor(0.9*n))\n",
    "validation_start = test_end\n",
    "validation_end = n\n",
    "\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]\n",
    "data_validation = data[np.arange(validation_start, validation_end), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on définit x et y\n",
    "X_train = data_train[:, :-2]\n",
    "y_train = data_train[:, -2:]\n",
    "X_test = data_test[:, :-2]\n",
    "y_test = data_test[:, -2:]\n",
    "X_validation = data_test[:, :-2]\n",
    "y_validation = data_test[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nombre de paramètres pour entrée X\n",
    "n_params = X_train.shape[1]\n",
    "# nombre de catégories (ici deux)\n",
    "n_classes = 2\n",
    "#learning rate\n",
    "learning_rate = 0.005\n",
    "\n",
    "# neurones\n",
    "n_neurons_1 = 2048\n",
    "n_neurons_2 = 1024\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_params])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, n_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialisation des poids et des biais\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# poids de la couche cachée\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_params, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "\n",
    "# poids en sortie\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_2, n_classes]))\n",
    "bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "# couches cachées\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "\n",
    "# couche de sortie\n",
    "out = tf.add(tf.matmul(hidden_2, W_out), bias_out)\n",
    "\n",
    "# fonction de cout\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=Y))\n",
    "\n",
    "# fonction d'optimisation (descente de gradient)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.005).minimize(cost)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost=0.693914577\n",
      "Epoch: 0006 cost=0.679955676\n",
      "Epoch: 0011 cost=0.671332818\n",
      "Epoch: 0016 cost=0.663313736\n",
      "Epoch: 0021 cost=0.654937893\n",
      "Epoch: 0026 cost=0.646566366\n",
      "Epoch: 0031 cost=0.638229202\n",
      "Epoch: 0036 cost=0.631207055\n",
      "Epoch: 0041 cost=0.624564221\n",
      "Epoch: 0046 cost=0.620619909\n",
      "Epoch: 0051 cost=0.616999960\n",
      "Epoch: 0056 cost=0.614886055\n",
      "Epoch: 0061 cost=0.613879448\n",
      "Epoch: 0066 cost=0.613134370\n",
      "Epoch: 0071 cost=0.611953735\n",
      "Epoch: 0076 cost=0.611899098\n",
      "Epoch: 0081 cost=0.611043771\n",
      "Epoch: 0086 cost=0.610667638\n",
      "Epoch: 0091 cost=0.609911061\n",
      "Epoch: 0096 cost=0.610361455\n",
      "Optimization Finished!\n",
      "Accuracy: 0.66501904\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_epochs = 50\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        # on fait une permutation sur les données d'entraînement\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "        X_train = X_train[shuffle_indices]\n",
    "        y_train = y_train[shuffle_indices]\n",
    "    \n",
    "        avg_cost = 0.\n",
    "        total_batch = len(y_train) // batch_size\n",
    "        # Boucle sur tous les batchs\n",
    "        for i in range(total_batch):\n",
    "            start = i * batch_size\n",
    "            batch_x = X_train[start:start + batch_size]\n",
    "            batch_y = y_train[start:start + batch_size]\n",
    "\n",
    "            _, c = sess.run([train_op, cost], feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            # on calcule le cout moyen\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"Epoch:\", '%03d' % (epoch+1), \"cost={:.6f}\".format(avg_cost))\n",
    "    print(\"Optimisation terminée !\")\n",
    "    \n",
    "    # Test model\n",
    "    pred = tf.nn.softmax(out)  # Apply softmax to logits\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({X: X_validation, Y: y_validation}))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
