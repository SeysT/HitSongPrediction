{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31034, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from csv import reader\n",
    "\n",
    "data = pd.read_csv('./Data/dataset.csv', delimiter='\\t')\n",
    "\n",
    "# On supprime champs non pertinents\n",
    "data = data.drop(['duration', 'artist_terms_freq', 'artist_familiarity', 'artist_id', 'artist_terms_weight', 'danceability', 'energy', 'path', 'file', 'similar_artists', 'title', 'year', 'latitude', 'longitude', 'midi_name'], axis=1)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# On supprime les données sans hotttnesss ou avec hotttnesss = 0 (non calculée)\n",
    "data = data.dropna(axis=0, how='any')\n",
    "data = data[data['hotttnesss'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        artist_terms  key  mode  loudness  \\\n",
      "2  [b'hard rock' b'heavy metal' b'blues-rock' b'c...    7     1    -5.271   \n",
      "5  [b'folk rock' b'singer-songwriter' b'rock' b'a...    2     1   -15.164   \n",
      "6  [b'soft rock' b'blues-rock' b'pop rock' b'coun...    9     1    -8.531   \n",
      "7  [b'outlaw country' b'country rock' b'southern ...    9     1    -6.291   \n",
      "9  [b'hip hop' b'rap' b'funk' b'r&b' b'pop' b'sou...   11     0    -4.882   \n",
      "\n",
      "     tempo  hotttnesss  \n",
      "2  150.062    0.684136  \n",
      "5  103.905    0.830423  \n",
      "6  180.149    0.767728  \n",
      "7  185.061    0.215080  \n",
      "9  105.206    0.624425  \n",
      "(13152, 6)\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout de genres principaux\n",
    "data['rock'] = data['artist_terms'].apply(lambda x: int('rock' in x))\n",
    "data['pop'] = data['artist_terms'].apply(lambda x: int('pop' in x))\n",
    "data['rap'] = data['artist_terms'].apply(lambda x: int('rap' in x))\n",
    "data['country'] = data['artist_terms'].apply(lambda x: int('country' in x))\n",
    "data['classical'] = data['artist_terms'].apply(lambda x: int('classical' in x))\n",
    "data['jazz'] = data['artist_terms'].apply(lambda x: int('jazz' in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on laisse de côté le champ \"artist_terms\" qui est non numérique\n",
    "data = data.drop(['artist_terms'], axis=1)\n",
    "\n",
    "# on place la colonne \"hotttnesss en fin de dataframe\"\n",
    "new_order = ['key', 'mode', 'loudness', 'tempo', 'rock', 'pop', 'rap', 'country', 'classical', 'jazz', 'hotttnesss']\n",
    "data = data[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dimensions of dataset\n",
    "n = data.shape[0]\n",
    "p = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on convertit data en array numpy\n",
    "data = data.values\n",
    "\n",
    "# on change toutes les valeurs en positif\n",
    "data = np.absolute(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on divise chaque colonne par le max de cettte colonne pour que chaque entrée soit comprise entre 0 et 1\n",
    "data = data*1./np.max(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# données d'entraînement, de test et de validation\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.7*n))\n",
    "test_start = train_end\n",
    "test_end = int(np.floor(0.9*n))\n",
    "validation_start = test_end\n",
    "validation_end = n\n",
    "\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]\n",
    "data_validation = data[np.arange(validation_start, validation_end), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on définit x et y\n",
    "X_train = data_train[:, :-1]\n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "X_validation = data_test[:, :-1]\n",
    "y_validation = data_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nombre de paramètres pour entrée X\n",
    "n_params = X_train.shape[1]\n",
    "\n",
    "# neurones\n",
    "n_neurons_1 = 2048\n",
    "n_neurons_2 = 1024\n",
    "\n",
    "# session\n",
    "net = tf.InteractiveSession()\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_params])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialisation des poids et des biais\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# poids de la couche cachée\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_params, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "\n",
    "# poids en sortie\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_2, 1]))\n",
    "bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "# couches cachées\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "\n",
    "# couche de sortie\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_2, W_out), bias_out))\n",
    "\n",
    "# fonction de cout\n",
    "cost = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# fonction d'optimisation (descente de gradient)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.005).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch numero 0\n",
      "MSE Train:  0.24904741\n",
      "MSE Test:  0.24744934\n",
      "MSE Train:  0.04297534\n",
      "MSE Test:  0.042421736\n",
      "MSE Train:  0.040933657\n",
      "MSE Test:  0.040517952\n",
      "epoch numero 1\n",
      "MSE Train:  0.039736\n",
      "MSE Test:  0.039393127\n",
      "MSE Train:  0.038848083\n",
      "MSE Test:  0.038542837\n",
      "MSE Train:  0.038218256\n",
      "MSE Test:  0.037985608\n",
      "epoch numero 2\n",
      "MSE Train:  0.037784133\n",
      "MSE Test:  0.037595663\n",
      "MSE Train:  0.037534237\n",
      "MSE Test:  0.03735617\n",
      "MSE Train:  0.037217945\n",
      "MSE Test:  0.03710662\n",
      "epoch numero 3\n",
      "MSE Train:  0.037033405\n",
      "MSE Test:  0.03696828\n",
      "MSE Train:  0.036867633\n",
      "MSE Test:  0.03678888\n",
      "MSE Train:  0.036733247\n",
      "MSE Test:  0.0366784\n",
      "epoch numero 4\n",
      "MSE Train:  0.036669526\n",
      "MSE Test:  0.036648218\n",
      "MSE Train:  0.036583778\n",
      "MSE Test:  0.036531407\n",
      "MSE Train:  0.03650036\n",
      "MSE Test:  0.036496375\n",
      "epoch numero 5\n",
      "MSE Train:  0.036421407\n",
      "MSE Test:  0.036411867\n",
      "MSE Train:  0.03635225\n",
      "MSE Test:  0.03633125\n",
      "MSE Train:  0.036292505\n",
      "MSE Test:  0.036261547\n",
      "epoch numero 6\n",
      "MSE Train:  0.03626771\n",
      "MSE Test:  0.036264338\n",
      "MSE Train:  0.036223337\n",
      "MSE Test:  0.036224194\n",
      "MSE Train:  0.03614954\n",
      "MSE Test:  0.036115594\n",
      "epoch numero 7\n",
      "MSE Train:  0.036146972\n",
      "MSE Test:  0.0361104\n",
      "MSE Train:  0.03610362\n",
      "MSE Test:  0.03611123\n",
      "MSE Train:  0.03605289\n",
      "MSE Test:  0.036016755\n",
      "epoch numero 8\n",
      "MSE Train:  0.03601954\n",
      "MSE Test:  0.035999857\n",
      "MSE Train:  0.03599207\n",
      "MSE Test:  0.03596608\n",
      "MSE Train:  0.035957526\n",
      "MSE Test:  0.03593374\n",
      "epoch numero 9\n",
      "MSE Train:  0.035937473\n",
      "MSE Test:  0.035909537\n",
      "MSE Train:  0.035914287\n",
      "MSE Test:  0.03587834\n",
      "MSE Train:  0.035889804\n",
      "MSE Test:  0.03586061\n",
      "epoch numero 10\n",
      "MSE Train:  0.035877008\n",
      "MSE Test:  0.035871115\n",
      "MSE Train:  0.03585291\n",
      "MSE Test:  0.03581988\n",
      "MSE Train:  0.03582141\n",
      "MSE Test:  0.0358031\n",
      "epoch numero 11\n",
      "MSE Train:  0.035851903\n",
      "MSE Test:  0.035850212\n",
      "MSE Train:  0.035785306\n",
      "MSE Test:  0.035758696\n",
      "MSE Train:  0.03577891\n",
      "MSE Test:  0.035770133\n",
      "epoch numero 12\n",
      "MSE Train:  0.035751186\n",
      "MSE Test:  0.03571772\n",
      "MSE Train:  0.03579882\n",
      "MSE Test:  0.03572937\n",
      "MSE Train:  0.03572796\n",
      "MSE Test:  0.035721317\n",
      "epoch numero 13\n",
      "MSE Train:  0.035715465\n",
      "MSE Test:  0.03570619\n",
      "MSE Train:  0.035685305\n",
      "MSE Test:  0.03565277\n",
      "MSE Train:  0.03568829\n",
      "MSE Test:  0.035687312\n",
      "epoch numero 14\n",
      "MSE Train:  0.035655957\n",
      "MSE Test:  0.035627753\n",
      "MSE Train:  0.035665467\n",
      "MSE Test:  0.035607085\n",
      "MSE Train:  0.035646755\n",
      "MSE Test:  0.03559854\n",
      "epoch numero 15\n",
      "MSE Train:  0.03562995\n",
      "MSE Test:  0.035631787\n",
      "MSE Train:  0.03561121\n",
      "MSE Test:  0.03560963\n",
      "MSE Train:  0.03562984\n",
      "MSE Test:  0.035617426\n",
      "epoch numero 16\n",
      "MSE Train:  0.03558411\n",
      "MSE Test:  0.03555837\n",
      "MSE Train:  0.03556844\n",
      "MSE Test:  0.035532694\n",
      "MSE Train:  0.035610165\n",
      "MSE Test:  0.03561606\n",
      "epoch numero 17\n",
      "MSE Train:  0.03553726\n",
      "MSE Test:  0.03552417\n",
      "MSE Train:  0.035567224\n",
      "MSE Test:  0.035580866\n",
      "MSE Train:  0.035557117\n",
      "MSE Test:  0.03551548\n",
      "epoch numero 18\n",
      "MSE Train:  0.035509814\n",
      "MSE Test:  0.03549076\n",
      "MSE Train:  0.03555496\n",
      "MSE Test:  0.035588026\n",
      "MSE Train:  0.035488028\n",
      "MSE Test:  0.035471182\n",
      "epoch numero 19\n",
      "MSE Train:  0.03548049\n",
      "MSE Test:  0.035457436\n",
      "MSE Train:  0.035516996\n",
      "MSE Test:  0.03548633\n",
      "MSE Train:  0.035446443\n",
      "MSE Test:  0.035431817\n",
      "epoch numero 20\n",
      "MSE Train:  0.035436768\n",
      "MSE Test:  0.035440564\n",
      "MSE Train:  0.03544294\n",
      "MSE Test:  0.035429478\n",
      "MSE Train:  0.035466727\n",
      "MSE Test:  0.035496548\n",
      "epoch numero 21\n",
      "MSE Train:  0.03544515\n",
      "MSE Test:  0.035417046\n",
      "MSE Train:  0.03544485\n",
      "MSE Test:  0.035468344\n",
      "MSE Train:  0.035384305\n",
      "MSE Test:  0.035366587\n",
      "epoch numero 22\n",
      "MSE Train:  0.035382763\n",
      "MSE Test:  0.035399206\n",
      "MSE Train:  0.03541196\n",
      "MSE Test:  0.035453014\n",
      "MSE Train:  0.03536955\n",
      "MSE Test:  0.03536332\n",
      "epoch numero 23\n",
      "MSE Train:  0.035344448\n",
      "MSE Test:  0.03535645\n",
      "MSE Train:  0.03537807\n",
      "MSE Test:  0.035352983\n",
      "MSE Train:  0.03534224\n",
      "MSE Test:  0.03533024\n",
      "epoch numero 24\n",
      "MSE Train:  0.035317242\n",
      "MSE Test:  0.035329085\n",
      "MSE Train:  0.03530822\n",
      "MSE Test:  0.03532205\n",
      "MSE Train:  0.035341237\n",
      "MSE Test:  0.035339948\n",
      "epoch numero 25\n",
      "MSE Train:  0.03531184\n",
      "MSE Test:  0.035307992\n",
      "MSE Train:  0.03530518\n",
      "MSE Test:  0.035321355\n",
      "MSE Train:  0.035278346\n",
      "MSE Test:  0.03528993\n",
      "epoch numero 26\n",
      "MSE Train:  0.035285193\n",
      "MSE Test:  0.035322838\n",
      "MSE Train:  0.03526261\n",
      "MSE Test:  0.035265256\n",
      "MSE Train:  0.03524954\n",
      "MSE Test:  0.035264954\n",
      "epoch numero 27\n",
      "MSE Train:  0.03524969\n",
      "MSE Test:  0.03528767\n",
      "MSE Train:  0.035233837\n",
      "MSE Test:  0.035259224\n",
      "MSE Train:  0.035318844\n",
      "MSE Test:  0.035304163\n",
      "epoch numero 28\n",
      "MSE Train:  0.035215355\n",
      "MSE Test:  0.035244662\n",
      "MSE Train:  0.03520982\n",
      "MSE Test:  0.035224844\n",
      "MSE Train:  0.0352102\n",
      "MSE Test:  0.03521374\n",
      "epoch numero 29\n",
      "MSE Train:  0.035191838\n",
      "MSE Test:  0.03522192\n",
      "MSE Train:  0.03518426\n",
      "MSE Test:  0.03521307\n",
      "MSE Train:  0.035207815\n",
      "MSE Test:  0.03521067\n",
      "epoch numero 30\n",
      "MSE Train:  0.035170563\n",
      "MSE Test:  0.03521002\n",
      "MSE Train:  0.035188522\n",
      "MSE Test:  0.03524638\n",
      "MSE Train:  0.035194486\n",
      "MSE Test:  0.03526258\n",
      "epoch numero 31\n",
      "MSE Train:  0.035150327\n",
      "MSE Test:  0.03519156\n",
      "MSE Train:  0.03522046\n",
      "MSE Test:  0.035286948\n",
      "MSE Train:  0.035133716\n",
      "MSE Test:  0.035172455\n",
      "epoch numero 32\n",
      "MSE Train:  0.035127588\n",
      "MSE Test:  0.03517106\n",
      "MSE Train:  0.03513646\n",
      "MSE Test:  0.035152253\n",
      "MSE Train:  0.035112258\n",
      "MSE Test:  0.03514944\n",
      "epoch numero 33\n",
      "MSE Train:  0.0351099\n",
      "MSE Test:  0.035159394\n",
      "MSE Train:  0.03509898\n",
      "MSE Test:  0.035146136\n",
      "MSE Train:  0.035119172\n",
      "MSE Test:  0.03519219\n",
      "epoch numero 34\n",
      "MSE Train:  0.03509301\n",
      "MSE Test:  0.035131514\n",
      "MSE Train:  0.035149787\n",
      "MSE Test:  0.03524535\n",
      "MSE Train:  0.035073303\n",
      "MSE Test:  0.03511849\n",
      "epoch numero 35\n",
      "MSE Train:  0.035113167\n",
      "MSE Test:  0.035131495\n",
      "MSE Train:  0.03507252\n",
      "MSE Test:  0.035096705\n",
      "MSE Train:  0.035062965\n",
      "MSE Test:  0.035129286\n",
      "epoch numero 36\n",
      "MSE Train:  0.035052218\n",
      "MSE Test:  0.0351114\n",
      "MSE Train:  0.03506446\n",
      "MSE Test:  0.035102032\n",
      "MSE Train:  0.03503857\n",
      "MSE Test:  0.035087064\n",
      "epoch numero 37\n",
      "MSE Train:  0.035045598\n",
      "MSE Test:  0.035115153\n",
      "MSE Train:  0.035027873\n",
      "MSE Test:  0.035084948\n",
      "MSE Train:  0.03502678\n",
      "MSE Test:  0.03508372\n",
      "epoch numero 38\n",
      "MSE Train:  0.035070874\n",
      "MSE Test:  0.03515909\n",
      "MSE Train:  0.03500776\n",
      "MSE Test:  0.035074774\n",
      "MSE Train:  0.035015598\n",
      "MSE Test:  0.03506511\n",
      "epoch numero 39\n",
      "MSE Train:  0.034997135\n",
      "MSE Test:  0.035055384\n",
      "MSE Train:  0.034993276\n",
      "MSE Test:  0.035043195\n",
      "MSE Train:  0.03499064\n",
      "MSE Test:  0.03504\n",
      "epoch numero 40\n",
      "MSE Train:  0.034982175\n",
      "MSE Test:  0.035047732\n",
      "MSE Train:  0.034985997\n",
      "MSE Test:  0.035064086\n",
      "MSE Train:  0.035006903\n",
      "MSE Test:  0.035056144\n",
      "epoch numero 41\n",
      "MSE Train:  0.034995135\n",
      "MSE Test:  0.035046957\n",
      "MSE Train:  0.034963023\n",
      "MSE Test:  0.035041593\n",
      "MSE Train:  0.03495619\n",
      "MSE Test:  0.035029747\n",
      "epoch numero 42\n",
      "MSE Train:  0.03495386\n",
      "MSE Test:  0.03503528\n",
      "MSE Train:  0.03494951\n",
      "MSE Test:  0.035028666\n",
      "MSE Train:  0.034951188\n",
      "MSE Test:  0.034999028\n",
      "epoch numero 43\n",
      "MSE Train:  0.034935288\n",
      "MSE Test:  0.035013307\n",
      "MSE Train:  0.034946393\n",
      "MSE Test:  0.035048578\n",
      "MSE Train:  0.03492698\n",
      "MSE Test:  0.03501583\n",
      "epoch numero 44\n",
      "MSE Train:  0.03493464\n",
      "MSE Test:  0.03503091\n",
      "MSE Train:  0.0349182\n",
      "MSE Test:  0.03499149\n",
      "MSE Train:  0.03495965\n",
      "MSE Test:  0.035064857\n",
      "epoch numero 45\n",
      "MSE Train:  0.034929678\n",
      "MSE Test:  0.03499629\n",
      "MSE Train:  0.03491709\n",
      "MSE Test:  0.034999937\n",
      "MSE Train:  0.034918025\n",
      "MSE Test:  0.035005167\n",
      "epoch numero 46\n",
      "MSE Train:  0.03491988\n",
      "MSE Test:  0.034982342\n",
      "MSE Train:  0.034908257\n",
      "MSE Test:  0.034962416\n",
      "MSE Train:  0.034898777\n",
      "MSE Test:  0.03497259\n",
      "epoch numero 47\n",
      "MSE Train:  0.034979235\n",
      "MSE Test:  0.03511389\n",
      "MSE Train:  0.03489813\n",
      "MSE Test:  0.035021447\n",
      "MSE Train:  0.03488354\n",
      "MSE Test:  0.034971077\n",
      "epoch numero 48\n",
      "MSE Train:  0.03486776\n",
      "MSE Test:  0.034962613\n",
      "MSE Train:  0.03487444\n",
      "MSE Test:  0.034952644\n",
      "MSE Train:  0.034867384\n",
      "MSE Test:  0.03496133\n",
      "epoch numero 49\n",
      "MSE Train:  0.034877274\n",
      "MSE Test:  0.034951165\n",
      "MSE Train:  0.034911007\n",
      "MSE Test:  0.03496282\n",
      "MSE Train:  0.03496141\n",
      "MSE Test:  0.035099167\n",
      "epoch numero 50\n",
      "MSE Train:  0.034853425\n",
      "MSE Test:  0.03496749\n",
      "MSE Train:  0.03485506\n",
      "MSE Test:  0.034951232\n",
      "MSE Train:  0.03487203\n",
      "MSE Test:  0.035016265\n",
      "epoch numero 51\n",
      "MSE Train:  0.034892723\n",
      "MSE Test:  0.034960046\n",
      "MSE Train:  0.034837063\n",
      "MSE Test:  0.034942366\n",
      "MSE Train:  0.034842428\n",
      "MSE Test:  0.034954365\n",
      "epoch numero 52\n",
      "MSE Train:  0.034829758\n",
      "MSE Test:  0.03495219\n",
      "MSE Train:  0.03481908\n",
      "MSE Test:  0.03491622\n",
      "MSE Train:  0.034818787\n",
      "MSE Test:  0.034931373\n",
      "epoch numero 53\n",
      "MSE Train:  0.034808956\n",
      "MSE Test:  0.034929723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train:  0.03480616\n",
      "MSE Test:  0.034920353\n",
      "MSE Train:  0.03489744\n",
      "MSE Test:  0.034981553\n",
      "epoch numero 54\n",
      "MSE Train:  0.034821685\n",
      "MSE Test:  0.034956504\n",
      "MSE Train:  0.034796245\n",
      "MSE Test:  0.03491517\n",
      "MSE Train:  0.034812976\n",
      "MSE Test:  0.034924492\n",
      "epoch numero 55\n",
      "MSE Train:  0.03478956\n",
      "MSE Test:  0.034903634\n",
      "MSE Train:  0.034789216\n",
      "MSE Test:  0.0349063\n",
      "MSE Train:  0.0347801\n",
      "MSE Test:  0.03489712\n",
      "epoch numero 56\n",
      "MSE Train:  0.03478614\n",
      "MSE Test:  0.03492345\n",
      "MSE Train:  0.034795478\n",
      "MSE Test:  0.034901634\n",
      "MSE Train:  0.034849625\n",
      "MSE Test:  0.034994848\n",
      "epoch numero 57\n",
      "MSE Train:  0.03476784\n",
      "MSE Test:  0.03489741\n",
      "MSE Train:  0.034765564\n",
      "MSE Test:  0.034909923\n",
      "MSE Train:  0.03479773\n",
      "MSE Test:  0.034903005\n",
      "epoch numero 58\n",
      "MSE Train:  0.034818932\n",
      "MSE Test:  0.034978267\n",
      "MSE Train:  0.034778077\n",
      "MSE Test:  0.034925513\n",
      "MSE Train:  0.034846846\n",
      "MSE Test:  0.034930017\n",
      "epoch numero 59\n",
      "MSE Train:  0.034754578\n",
      "MSE Test:  0.03489592\n",
      "MSE Train:  0.0347606\n",
      "MSE Test:  0.03488274\n",
      "MSE Train:  0.034745917\n",
      "MSE Test:  0.034877673\n",
      "epoch numero 60\n",
      "MSE Train:  0.03474713\n",
      "MSE Test:  0.034893528\n",
      "MSE Train:  0.034742348\n",
      "MSE Test:  0.03486193\n",
      "MSE Train:  0.034734078\n",
      "MSE Test:  0.03486378\n",
      "epoch numero 61\n",
      "MSE Train:  0.034733817\n",
      "MSE Test:  0.034886803\n",
      "MSE Train:  0.034730658\n",
      "MSE Test:  0.034867465\n",
      "MSE Train:  0.03476462\n",
      "MSE Test:  0.034931522\n",
      "epoch numero 62\n",
      "MSE Train:  0.034765728\n",
      "MSE Test:  0.0348806\n",
      "MSE Train:  0.034759633\n",
      "MSE Test:  0.034877352\n",
      "MSE Train:  0.03473751\n",
      "MSE Test:  0.034896582\n",
      "epoch numero 63\n",
      "MSE Train:  0.034731936\n",
      "MSE Test:  0.034863107\n",
      "MSE Train:  0.03476312\n",
      "MSE Test:  0.034893084\n",
      "MSE Train:  0.034755263\n",
      "MSE Test:  0.03493061\n",
      "epoch numero 64\n",
      "MSE Train:  0.034704477\n",
      "MSE Test:  0.03485187\n",
      "MSE Train:  0.034726664\n",
      "MSE Test:  0.034889325\n",
      "MSE Train:  0.03470573\n",
      "MSE Test:  0.0348584\n",
      "epoch numero 65\n",
      "MSE Train:  0.034696393\n",
      "MSE Test:  0.034852535\n",
      "MSE Train:  0.03469985\n",
      "MSE Test:  0.03484115\n",
      "MSE Train:  0.034730736\n",
      "MSE Test:  0.034870207\n",
      "epoch numero 66\n",
      "MSE Train:  0.03469268\n",
      "MSE Test:  0.034836162\n",
      "MSE Train:  0.034687374\n",
      "MSE Test:  0.034853093\n",
      "MSE Train:  0.034755733\n",
      "MSE Test:  0.034880128\n",
      "epoch numero 67\n",
      "MSE Train:  0.034733888\n",
      "MSE Test:  0.03485884\n",
      "MSE Train:  0.03471532\n",
      "MSE Test:  0.034891736\n",
      "MSE Train:  0.034677994\n",
      "MSE Test:  0.034844764\n",
      "epoch numero 68\n",
      "MSE Train:  0.034680586\n",
      "MSE Test:  0.034861013\n",
      "MSE Train:  0.034669917\n",
      "MSE Test:  0.034845203\n",
      "MSE Train:  0.034669247\n",
      "MSE Test:  0.03483648\n",
      "epoch numero 69\n",
      "MSE Train:  0.034732748\n",
      "MSE Test:  0.03485892\n",
      "MSE Train:  0.034664333\n",
      "MSE Test:  0.034842532\n",
      "MSE Train:  0.03466031\n",
      "MSE Test:  0.03483052\n",
      "epoch numero 70\n",
      "MSE Train:  0.034668475\n",
      "MSE Test:  0.034820307\n",
      "MSE Train:  0.034666333\n",
      "MSE Test:  0.034857698\n",
      "MSE Train:  0.034657598\n",
      "MSE Test:  0.034860104\n",
      "epoch numero 71\n",
      "MSE Train:  0.03469086\n",
      "MSE Test:  0.03488619\n",
      "MSE Train:  0.03464757\n",
      "MSE Test:  0.034803893\n",
      "MSE Train:  0.034646403\n",
      "MSE Test:  0.034819882\n",
      "epoch numero 72\n",
      "MSE Train:  0.034646276\n",
      "MSE Test:  0.034814548\n",
      "MSE Train:  0.034644652\n",
      "MSE Test:  0.034836806\n",
      "MSE Train:  0.03464246\n",
      "MSE Test:  0.034835443\n",
      "epoch numero 73\n",
      "MSE Train:  0.03465138\n",
      "MSE Test:  0.034809373\n",
      "MSE Train:  0.0346368\n",
      "MSE Test:  0.03481242\n",
      "MSE Train:  0.03464318\n",
      "MSE Test:  0.034812134\n",
      "epoch numero 74\n",
      "MSE Train:  0.034667898\n",
      "MSE Test:  0.034875397\n",
      "MSE Train:  0.03466352\n",
      "MSE Test:  0.034865137\n",
      "MSE Train:  0.034655925\n",
      "MSE Test:  0.03483589\n",
      "epoch numero 75\n",
      "MSE Train:  0.034634754\n",
      "MSE Test:  0.03480467\n",
      "MSE Train:  0.034743544\n",
      "MSE Test:  0.034963947\n",
      "MSE Train:  0.034625914\n",
      "MSE Test:  0.034823526\n",
      "epoch numero 76\n",
      "MSE Train:  0.03461531\n",
      "MSE Test:  0.034805797\n",
      "MSE Train:  0.03461712\n",
      "MSE Test:  0.034806304\n",
      "MSE Train:  0.034615207\n",
      "MSE Test:  0.034799036\n",
      "epoch numero 77\n",
      "MSE Train:  0.03468741\n",
      "MSE Test:  0.034835022\n",
      "MSE Train:  0.034615017\n",
      "MSE Test:  0.034822885\n",
      "MSE Train:  0.034630835\n",
      "MSE Test:  0.0347906\n",
      "epoch numero 78\n",
      "MSE Train:  0.03465726\n",
      "MSE Test:  0.0348848\n",
      "MSE Train:  0.03466984\n",
      "MSE Test:  0.034834392\n",
      "MSE Train:  0.034607828\n",
      "MSE Test:  0.034812257\n",
      "epoch numero 79\n",
      "MSE Train:  0.034632206\n",
      "MSE Test:  0.034851592\n",
      "MSE Train:  0.03462653\n",
      "MSE Test:  0.03479747\n",
      "MSE Train:  0.034593217\n",
      "MSE Test:  0.034780804\n",
      "epoch numero 80\n",
      "MSE Train:  0.034589976\n",
      "MSE Test:  0.034790255\n",
      "MSE Train:  0.03458986\n",
      "MSE Test:  0.03479916\n",
      "MSE Train:  0.034597907\n",
      "MSE Test:  0.03480632\n",
      "epoch numero 81\n",
      "MSE Train:  0.034591235\n",
      "MSE Test:  0.034773104\n",
      "MSE Train:  0.03458471\n",
      "MSE Test:  0.034797773\n",
      "MSE Train:  0.034618583\n",
      "MSE Test:  0.034844954\n",
      "epoch numero 82\n",
      "MSE Train:  0.034646254\n",
      "MSE Test:  0.03488034\n",
      "MSE Train:  0.034610823\n",
      "MSE Test:  0.03482165\n",
      "MSE Train:  0.034577344\n",
      "MSE Test:  0.034774534\n",
      "epoch numero 83\n",
      "MSE Train:  0.034572855\n",
      "MSE Test:  0.034789525\n",
      "MSE Train:  0.034573436\n",
      "MSE Test:  0.03479918\n",
      "MSE Train:  0.0345721\n",
      "MSE Test:  0.034798488\n",
      "epoch numero 84\n",
      "MSE Train:  0.034576196\n",
      "MSE Test:  0.034769896\n",
      "MSE Train:  0.034565795\n",
      "MSE Test:  0.0347917\n",
      "MSE Train:  0.034567744\n",
      "MSE Test:  0.034768015\n",
      "epoch numero 85\n",
      "MSE Train:  0.034564774\n",
      "MSE Test:  0.034786347\n",
      "MSE Train:  0.034586653\n",
      "MSE Test:  0.034759082\n",
      "MSE Train:  0.0345659\n",
      "MSE Test:  0.034783565\n",
      "epoch numero 86\n",
      "MSE Train:  0.034555264\n",
      "MSE Test:  0.03477059\n",
      "MSE Train:  0.03455623\n",
      "MSE Test:  0.03475405\n",
      "MSE Train:  0.03456728\n",
      "MSE Test:  0.034770984\n",
      "epoch numero 87\n",
      "MSE Train:  0.03457811\n",
      "MSE Test:  0.034817934\n",
      "MSE Train:  0.03454899\n",
      "MSE Test:  0.034766268\n",
      "MSE Train:  0.034547713\n",
      "MSE Test:  0.03476363\n",
      "epoch numero 88\n",
      "MSE Train:  0.034626447\n",
      "MSE Test:  0.034891386\n",
      "MSE Train:  0.034616042\n",
      "MSE Test:  0.03486518\n",
      "MSE Train:  0.034541335\n",
      "MSE Test:  0.03475001\n",
      "epoch numero 89\n",
      "MSE Train:  0.034557648\n",
      "MSE Test:  0.034763552\n",
      "MSE Train:  0.034546398\n",
      "MSE Test:  0.034766424\n",
      "MSE Train:  0.034543958\n",
      "MSE Test:  0.03478847\n",
      "epoch numero 90\n",
      "MSE Train:  0.034631953\n",
      "MSE Test:  0.034899425\n",
      "MSE Train:  0.03453489\n",
      "MSE Test:  0.034756087\n",
      "MSE Train:  0.034623824\n",
      "MSE Test:  0.03481325\n",
      "epoch numero 91\n",
      "MSE Train:  0.034543116\n",
      "MSE Test:  0.034746077\n",
      "MSE Train:  0.034527436\n",
      "MSE Test:  0.034757186\n",
      "MSE Train:  0.034533296\n",
      "MSE Test:  0.034749515\n",
      "epoch numero 92\n",
      "MSE Train:  0.0345234\n",
      "MSE Test:  0.034752112\n",
      "MSE Train:  0.034563523\n",
      "MSE Test:  0.034762263\n",
      "MSE Train:  0.034525782\n",
      "MSE Test:  0.03476077\n",
      "epoch numero 93\n",
      "MSE Train:  0.034548208\n",
      "MSE Test:  0.034799773\n",
      "MSE Train:  0.0345286\n",
      "MSE Test:  0.03474847\n",
      "MSE Train:  0.034545522\n",
      "MSE Test:  0.034751374\n",
      "epoch numero 94\n",
      "MSE Train:  0.034522407\n",
      "MSE Test:  0.03476753\n",
      "MSE Train:  0.0345247\n",
      "MSE Test:  0.03473416\n",
      "MSE Train:  0.034515586\n",
      "MSE Test:  0.034732096\n",
      "epoch numero 95\n",
      "MSE Train:  0.034553614\n",
      "MSE Test:  0.034820408\n",
      "MSE Train:  0.03450896\n",
      "MSE Test:  0.03472884\n",
      "MSE Train:  0.03453101\n",
      "MSE Test:  0.034790047\n",
      "epoch numero 96\n",
      "MSE Train:  0.034524605\n",
      "MSE Test:  0.03474531\n",
      "MSE Train:  0.03452073\n",
      "MSE Test:  0.034798674\n",
      "MSE Train:  0.03464523\n",
      "MSE Test:  0.034938157\n",
      "epoch numero 97\n",
      "MSE Train:  0.034503914\n",
      "MSE Test:  0.034733694\n",
      "MSE Train:  0.034506526\n",
      "MSE Test:  0.034756947\n",
      "MSE Train:  0.034498934\n",
      "MSE Test:  0.03473744\n",
      "epoch numero 98\n",
      "MSE Train:  0.03449485\n",
      "MSE Test:  0.03474102\n",
      "MSE Train:  0.03449507\n",
      "MSE Test:  0.034762394\n",
      "MSE Train:  0.03449703\n",
      "MSE Test:  0.034756597\n",
      "epoch numero 99\n",
      "MSE Train:  0.03452931\n",
      "MSE Test:  0.03480804\n",
      "MSE Train:  0.03452675\n",
      "MSE Test:  0.034760926\n",
      "MSE Train:  0.0344992\n",
      "MSE Test:  0.034771886\n",
      "Optimisation terminée !\n"
     ]
    }
   ],
   "source": [
    "# Fit neural net\n",
    "batch_size = 64\n",
    "training_epochs = 100\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "\n",
    "    for e in range(training_epochs):\n",
    "        print('epoch numero %i' % e)\n",
    "\n",
    "        # Shuffle training data\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "        X_train = X_train[shuffle_indices]\n",
    "        y_train = y_train[shuffle_indices]\n",
    "\n",
    "        # Minibatch training\n",
    "        for i in range(0, len(y_train) // batch_size):\n",
    "            start = i * batch_size\n",
    "            batch_x = X_train[start:start + batch_size]\n",
    "            batch_y = y_train[start:start + batch_size]\n",
    "            # Run optimizer with batch\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "            # Show progress\n",
    "            if np.mod(i, 50) == 0:\n",
    "                # MSE train and test\n",
    "                mse_train.append(sess.run(cost, feed_dict={X: X_train, Y: y_train}))\n",
    "                mse_test.append(sess.run(cost, feed_dict={X: X_test, Y: y_test}))\n",
    "                print('MSE Train: ', mse_train[-1])\n",
    "                print('MSE Test: ', mse_test[-1])\n",
    "                # Prediction\n",
    "                pred = sess.run(out, feed_dict={X: X_test})\n",
    "                \n",
    "        valid = sess.run(out, feed_dict={X: X_validation})\n",
    "    print(\"Optimisation terminée !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analyse résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random = np.random.rand(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample =np.full(y_validation.shape, np.mean(y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03716221568025413"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_validation, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03474587197740862"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_validation, valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1 = np.absolute(y_validation - valid[0])\n",
    "test2 =  np.absolute(y_validation - sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15586158266306072\n",
      "0.16250320110518973\n"
     ]
    }
   ],
   "source": [
    "print(test1.mean())\n",
    "print(test2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12282853715092318"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_validation, random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03716221568025413"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nncg/kkSNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1acb47d7b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot()\n",
    "plt.plot([0,1], [0,1], color=\"r\")\n",
    "plt.scatter(valid[0] , y_validation)\n",
    "plt.xlabel('hotttnesss prédite')\n",
    "plt.ylabel('hotttnesss effective')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
